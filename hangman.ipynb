{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report,balanced_accuracy_score\n",
    "from collections import Counter\n",
    "import itertools\n",
    "import multiprocessing as mp\n",
    "import random\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: catboost in c:\\users\\shanttanu\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (1.2.5)\n",
      "Requirement already satisfied: graphviz in c:\\users\\shanttanu\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from catboost) (0.20.3)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\shanttanu\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from catboost) (3.7.1)\n",
      "Requirement already satisfied: numpy>=1.16.0 in c:\\users\\shanttanu\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from catboost) (1.24.2)\n",
      "Requirement already satisfied: pandas>=0.24 in c:\\users\\shanttanu\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from catboost) (2.0.3)\n",
      "Requirement already satisfied: scipy in c:\\users\\shanttanu\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from catboost) (1.10.1)\n",
      "Requirement already satisfied: plotly in c:\\users\\shanttanu\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from catboost) (5.24.0)\n",
      "Requirement already satisfied: six in c:\\users\\shanttanu\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from catboost) (1.16.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\shanttanu\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from pandas>=0.24->catboost) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\shanttanu\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from pandas>=0.24->catboost) (2023.3)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\shanttanu\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from pandas>=0.24->catboost) (2023.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\shanttanu\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from matplotlib->catboost) (1.0.7)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\shanttanu\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from matplotlib->catboost) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\shanttanu\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from matplotlib->catboost) (4.38.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\shanttanu\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from matplotlib->catboost) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\shanttanu\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from matplotlib->catboost) (23.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\shanttanu\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from matplotlib->catboost) (9.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\shanttanu\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from matplotlib->catboost) (3.0.9)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in c:\\users\\shanttanu\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from plotly->catboost) (9.0.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.1.2 -> 24.2\n",
      "[notice] To update, run: C:\\Users\\Shanttanu\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def build_dictionary(dictionary_file_location):\n",
    "#     text_file = open(dictionary_file_location,\"r\")\n",
    "#     full_dictionary = text_file.read().splitlines()\n",
    "#     text_file.close()\n",
    "#     return full_dictionary\n",
    "# words = build_dictionary(\"words_250000_train.txt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dictionary = build_dictionary(\"words_250000_train.txt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29\n"
     ]
    }
   ],
   "source": [
    "# sets = [set(x) for x in dictionary]\n",
    "# #find longest word in dictionary\n",
    "# max_len = 0\n",
    "# w = \"\"\n",
    "# for word in dictionary: \n",
    "#     if len(word) > max_len:\n",
    "#         max_len = len(word)\n",
    "#         w = word\n",
    "# print(max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# def get_combinations(letters):\n",
    "#     combinations = []\n",
    "#     for i in range(1,len(letters)+1):\n",
    "#         combinations += list(itertools.combinations(letters, i))\n",
    "#     return combinations\n",
    "# nos = [len(x) for x in sets]\n",
    "# freq = Counter(nos)\n",
    "# summ = 0\n",
    "# ss = \"abcdefghijklmnopqrstuvwxyz\"\n",
    "# for i in freq:\n",
    "#     summ += freq[i]*len(get_combinations(ss[:i]))\n",
    "value = {\"a\":1,\"b\":2,\"c\":3,\"d\":4,\"e\":5,\"f\":6,\"g\":7,\n",
    "         \"h\":8,\"i\":9,\"j\":10,\"k\":11,\"l\":12,\"m\":13,\"n\":14,\n",
    "         \"o\":15,\"p\":16,\"q\":17,\"r\":18,\"s\":19,\"t\":20,\"u\":21,\n",
    "         \"v\":22,\"w\":23,\"x\":24,\"y\":25,\"z\":26}\n",
    "\n",
    "         \n",
    "# def dataframemaker(dicc):    \n",
    "#     dfs = []\n",
    "\n",
    "#     for word in dicc:\n",
    "#         for comb in get_combinations(\"\".join(set(word))):\n",
    "#             #create an array of -1s of length 80\n",
    "#             num = np.full(80,-1)\n",
    "#             guess = np.full(26,0)\n",
    "#             #fill the array with the index of the letters in the word\n",
    "#             k=len(word)\n",
    "#             for i in range(k):\n",
    "#                 if(word[i] in comb):\n",
    "#                     num[i] = value[word[i]]\n",
    "#                     num[80-k+i] = value[word[i]]\n",
    "#                 else:\n",
    "#                     num[i] = 0\n",
    "#                     num[80-k+i] = 0\n",
    "#                     guess[value[word[i]]-1] = 1\n",
    "#             dfs.append(num.tolist()+guess.tolist())\n",
    "    \n",
    "#     return pd.DataFrame(dfs,dtype=np.int8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# dataset = []\n",
    "\n",
    "# for dicc in np.array_split(dictionary,10):\n",
    "    \n",
    "#     print(\"1 \\n\")\n",
    "\n",
    "#     manager = mp.Manager()\n",
    "#     pool = mp.Pool()\n",
    "\n",
    "#     dictsplit = np.array_split(dicc,128)\n",
    "\n",
    "#     datas = pool.map(dataframemaker,dictsplit)\n",
    "#     pool.close()\n",
    "#     pool.join()\n",
    "\n",
    "#     finaldata = pd.concat(datas).reset_index(drop=True)\n",
    "\n",
    "#     del datas\n",
    "\n",
    "#     finaldata.columns = [str(x) for x in range(80)]+[x for x in \"abcdefghijklmnopqrstuvwxyz\"]\n",
    "#     dataset.append(finaldata)\n",
    "#     del finaldata\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset = pd.concat(dataset).reset_index(drop=True)\n",
    "# dataset.to_parquet(\"fd.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_parquet(\"fd.parquet\")\n",
    "alpha = \"abcdefghijklmnopqrstuvwxyz\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyarrow"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.1.2 -> 24.2\n",
      "[notice] To update, run: C:\\Users\\Shanttanu\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Downloading pyarrow-17.0.0-cp310-cp310-win_amd64.whl (25.1 MB)\n",
      "                                              0.0/25.1 MB ? eta -:--:--\n",
      "                                              0.4/25.1 MB 11.8 MB/s eta 0:00:03\n",
      "     -                                        0.8/25.1 MB 10.2 MB/s eta 0:00:03\n",
      "     -                                        1.0/25.1 MB 9.2 MB/s eta 0:00:03\n",
      "     --                                       1.4/25.1 MB 9.0 MB/s eta 0:00:03\n",
      "     ---                                      2.0/25.1 MB 9.1 MB/s eta 0:00:03\n",
      "     ---                                      2.4/25.1 MB 9.0 MB/s eta 0:00:03\n",
      "     ----                                     3.0/25.1 MB 10.1 MB/s eta 0:00:03\n",
      "     -----                                    3.6/25.1 MB 10.0 MB/s eta 0:00:03\n",
      "     ------                                   4.0/25.1 MB 9.8 MB/s eta 0:00:03\n",
      "     ------                                   4.4/25.1 MB 9.6 MB/s eta 0:00:03\n",
      "     -------                                  4.8/25.1 MB 9.5 MB/s eta 0:00:03\n",
      "     --------                                 5.3/25.1 MB 9.5 MB/s eta 0:00:03\n",
      "     ---------                                5.8/25.1 MB 9.4 MB/s eta 0:00:03\n",
      "     ---------                                6.2/25.1 MB 9.7 MB/s eta 0:00:02\n",
      "     ----------                               6.7/25.1 MB 9.7 MB/s eta 0:00:02\n",
      "     -----------                              7.2/25.1 MB 9.8 MB/s eta 0:00:02\n",
      "     ------------                             7.7/25.1 MB 9.8 MB/s eta 0:00:02\n",
      "     ------------                             8.1/25.1 MB 9.8 MB/s eta 0:00:02\n",
      "     -------------                            8.7/25.1 MB 10.1 MB/s eta 0:00:02\n",
      "     --------------                           9.2/25.1 MB 10.2 MB/s eta 0:00:02\n",
      "     ---------------                          9.7/25.1 MB 10.2 MB/s eta 0:00:02\n",
      "     ---------------                         10.2/25.1 MB 10.2 MB/s eta 0:00:02\n",
      "     ----------------                        10.8/25.1 MB 10.2 MB/s eta 0:00:02\n",
      "     -----------------                       11.1/25.1 MB 10.2 MB/s eta 0:00:02\n",
      "     -----------------                       11.6/25.1 MB 10.2 MB/s eta 0:00:02\n",
      "     ------------------                      12.1/25.1 MB 10.4 MB/s eta 0:00:02\n",
      "     -------------------                     12.5/25.1 MB 10.4 MB/s eta 0:00:02\n",
      "     --------------------                    13.1/25.1 MB 10.4 MB/s eta 0:00:02\n",
      "     --------------------                    13.5/25.1 MB 10.2 MB/s eta 0:00:02\n",
      "     ---------------------                   14.1/25.1 MB 10.6 MB/s eta 0:00:02\n",
      "     ----------------------                  14.6/25.1 MB 10.6 MB/s eta 0:00:02\n",
      "     -----------------------                 15.0/25.1 MB 10.7 MB/s eta 0:00:01\n",
      "     -----------------------                 15.4/25.1 MB 10.4 MB/s eta 0:00:01\n",
      "     ------------------------                15.9/25.1 MB 10.7 MB/s eta 0:00:01\n",
      "     -------------------------               16.5/25.1 MB 10.9 MB/s eta 0:00:01\n",
      "     --------------------------              16.9/25.1 MB 10.7 MB/s eta 0:00:01\n",
      "     --------------------------              17.3/25.1 MB 10.6 MB/s eta 0:00:01\n",
      "     ---------------------------             18.0/25.1 MB 10.7 MB/s eta 0:00:01\n",
      "     ----------------------------            18.5/25.1 MB 10.7 MB/s eta 0:00:01\n",
      "     -----------------------------           19.0/25.1 MB 10.7 MB/s eta 0:00:01\n",
      "     ------------------------------          19.5/25.1 MB 10.4 MB/s eta 0:00:01\n",
      "     -------------------------------         20.0/25.1 MB 10.6 MB/s eta 0:00:01\n",
      "     -------------------------------         20.5/25.1 MB 10.6 MB/s eta 0:00:01\n",
      "     --------------------------------        20.9/25.1 MB 10.4 MB/s eta 0:00:01\n",
      "     ---------------------------------       21.5/25.1 MB 10.7 MB/s eta 0:00:01\n",
      "     ----------------------------------      22.1/25.1 MB 10.9 MB/s eta 0:00:01\n",
      "     -----------------------------------     22.6/25.1 MB 10.9 MB/s eta 0:00:01\n",
      "     -----------------------------------     23.2/25.1 MB 11.1 MB/s eta 0:00:01\n",
      "     ------------------------------------    23.6/25.1 MB 10.9 MB/s eta 0:00:01\n",
      "     -------------------------------------   24.2/25.1 MB 10.9 MB/s eta 0:00:01\n",
      "     --------------------------------------  24.7/25.1 MB 10.9 MB/s eta 0:00:01\n",
      "     --------------------------------------  25.1/25.1 MB 11.1 MB/s eta 0:00:01\n",
      "     --------------------------------------  25.1/25.1 MB 11.1 MB/s eta 0:00:01\n",
      "     --------------------------------------  25.1/25.1 MB 11.1 MB/s eta 0:00:01\n",
      "     --------------------------------------  25.1/25.1 MB 11.1 MB/s eta 0:00:01\n",
      "     --------------------------------------  25.1/25.1 MB 11.1 MB/s eta 0:00:01\n",
      "     --------------------------------------  25.1/25.1 MB 11.1 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 25.1/25.1 MB 8.2 MB/s eta 0:00:00\n",
      "Requirement already satisfied: numpy>=1.16.6 in c:\\users\\shanttanu\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from pyarrow) (1.24.2)\n",
      "Installing collected packages: pyarrow\n",
      "Successfully installed pyarrow-17.0.0\n",
      "Collecting fastparquet\n",
      "  Downloading fastparquet-2024.5.0-cp310-cp310-win_amd64.whl (672 kB)\n",
      "                                              0.0/672.1 kB ? eta -:--:--\n",
      "     --------------                         256.0/672.1 kB 5.2 MB/s eta 0:00:01\n",
      "     ----------------------------------     614.4/672.1 kB 7.7 MB/s eta 0:00:01\n",
      "     -------------------------------------- 672.1/672.1 kB 5.3 MB/s eta 0:00:00\n",
      "Requirement already satisfied: pandas>=1.5.0 in c:\\users\\shanttanu\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from fastparquet) (2.0.3)\n",
      "Requirement already satisfied: numpy in c:\\users\\shanttanu\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from fastparquet) (1.24.2)\n",
      "Collecting cramjam>=2.3 (from fastparquet)\n",
      "  Downloading cramjam-2.8.3-cp310-none-win_amd64.whl (1.6 MB)\n",
      "                                              0.0/1.6 MB ? eta -:--:--\n",
      "     ----------                               0.4/1.6 MB 13.5 MB/s eta 0:00:01\n",
      "     ---------------------                    0.9/1.6 MB 11.3 MB/s eta 0:00:01\n",
      "     ------------------------------------     1.5/1.6 MB 11.9 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 1.6/1.6 MB 9.5 MB/s eta 0:00:00\n",
      "Requirement already satisfied: fsspec in c:\\users\\shanttanu\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from fastparquet) (2023.9.2)\n",
      "Requirement already satisfied: packaging in c:\\users\\shanttanu\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from fastparquet) (23.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\shanttanu\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from pandas>=1.5.0->fastparquet) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\shanttanu\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from pandas>=1.5.0->fastparquet) (2023.3)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\shanttanu\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from pandas>=1.5.0->fastparquet) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\shanttanu\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from python-dateutil>=2.8.2->pandas>=1.5.0->fastparquet) (1.16.0)\n",
      "Installing collected packages: cramjam, fastparquet\n",
      "Successfully installed cramjam-2.8.3 fastparquet-2024.5.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.1.2 -> 24.2\n",
      "[notice] To update, run: C:\\Users\\Shanttanu\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install pyarrow\n",
    "!pip install fastparquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiLabelCatBoostClassifier:\n",
    "    def __init__(self, num_classes=26, catboost_params=None):\n",
    "        # Initialize 26 CatBoost classifiers, one for each label\n",
    "        self.classifiers = [CatBoostClassifier(iterations=1500) for _ in range(num_classes)]\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        # X is the feature matrix, y is a binary matrix indicating label presence\n",
    "        for i in range(len(self.classifiers)):\n",
    "            # Train each classifier on the corresponding label\n",
    "            # dd = y[y[alpha[i]] == 0].sample(len(y) - 2*len(y[y[alpha[i]] == 1])).index\n",
    "            dd = []\n",
    "            self.classifiers[i].fit(X.drop(dd), y[alpha[i]].drop(dd), verbose=100)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        # Predict probabilities for each label\n",
    "        predictions = np.zeros((len(X), len(self.classifiers)))\n",
    "        for i, clf in enumerate(self.classifiers):\n",
    "            predictions[:, i] = clf.predict_proba(X)[:, 1]  # Probability of class '1'\n",
    "        return predictions\n",
    "    \n",
    "    def save(self, filename):\n",
    "        # Save the model to a pickle file\n",
    "        with open(filename, 'wb') as file:\n",
    "            pickle.dump(self, file)\n",
    "    \n",
    "    @classmethod\n",
    "    def load(cls, filename):\n",
    "        # Load the model from a pickle file\n",
    "        with open(filename, 'rb') as file:\n",
    "            model = pickle.load(file)\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 2.44 GiB for an array with shape (26, 100725482) and data type int8",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m#train test split\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n\u001b[1;32m----> 5\u001b[0m X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m train_test_split(dataset[[\u001b[38;5;28mstr\u001b[39m(x) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m80\u001b[39m)]], \u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[43mx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mabcdefghijklmnopqrstuvwxyz\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.01\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[0;32m      7\u001b[0m model\u001b[38;5;241m.\u001b[39mfit(X_train,y_train)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\core\\frame.py:3773\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3770\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n\u001b[0;32m   3771\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mwhere(indexer)[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m-> 3773\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_take_with_is_copy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3775\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_single_key:\n\u001b[0;32m   3776\u001b[0m     \u001b[38;5;66;03m# What does looking for a single key in a non-unique index return?\u001b[39;00m\n\u001b[0;32m   3777\u001b[0m     \u001b[38;5;66;03m# The behavior is inconsistent. It returns a Series, except when\u001b[39;00m\n\u001b[0;32m   3778\u001b[0m     \u001b[38;5;66;03m# - the key itself is repeated (test on data.shape, #9519), or\u001b[39;00m\n\u001b[0;32m   3779\u001b[0m     \u001b[38;5;66;03m# - we have a MultiIndex on columns (test on self.columns, #21309)\u001b[39;00m\n\u001b[0;32m   3780\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns, MultiIndex):\n\u001b[0;32m   3781\u001b[0m         \u001b[38;5;66;03m# GH#26490 using data[key] can cause RecursionError\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\core\\generic.py:3948\u001b[0m, in \u001b[0;36mNDFrame._take_with_is_copy\u001b[1;34m(self, indices, axis)\u001b[0m\n\u001b[0;32m   3940\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_take_with_is_copy\u001b[39m(\u001b[38;5;28mself\u001b[39m: NDFrameT, indices, axis: Axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m NDFrameT:\n\u001b[0;32m   3941\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   3942\u001b[0m \u001b[38;5;124;03m    Internal version of the `take` method that sets the `_is_copy`\u001b[39;00m\n\u001b[0;32m   3943\u001b[0m \u001b[38;5;124;03m    attribute to keep track of the parent dataframe (using in indexing\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3946\u001b[0m \u001b[38;5;124;03m    See the docstring of `take` for full explanation of the parameters.\u001b[39;00m\n\u001b[0;32m   3947\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 3948\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_take\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindices\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3949\u001b[0m     \u001b[38;5;66;03m# Maybe set copy if we didn't actually change the index.\u001b[39;00m\n\u001b[0;32m   3950\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m result\u001b[38;5;241m.\u001b[39m_get_axis(axis)\u001b[38;5;241m.\u001b[39mequals(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_axis(axis)):\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\core\\generic.py:3932\u001b[0m, in \u001b[0;36mNDFrame._take\u001b[1;34m(self, indices, axis, convert_indices)\u001b[0m\n\u001b[0;32m   3924\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m   3925\u001b[0m         axis \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m   3926\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m indices\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   3927\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m using_copy_on_write()\n\u001b[0;32m   3928\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m is_range_indexer(indices, \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m))\n\u001b[0;32m   3929\u001b[0m     ):\n\u001b[0;32m   3930\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy(deep\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m-> 3932\u001b[0m new_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mgr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtake\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   3933\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindices\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3934\u001b[0m \u001b[43m    \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_block_manager_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3935\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverify\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   3936\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconvert_indices\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert_indices\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3937\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3938\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_constructor(new_data)\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtake\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\core\\internals\\managers.py:963\u001b[0m, in \u001b[0;36mBaseBlockManager.take\u001b[1;34m(self, indexer, axis, verify, convert_indices)\u001b[0m\n\u001b[0;32m    960\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m maybe_convert_indices(indexer, n, verify\u001b[38;5;241m=\u001b[39mverify)\n\u001b[0;32m    962\u001b[0m new_labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes[axis]\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[1;32m--> 963\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreindex_indexer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    964\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnew_axis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnew_labels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    965\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindexer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    966\u001b[0m \u001b[43m    \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    967\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_dups\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    968\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    969\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\core\\internals\\managers.py:740\u001b[0m, in \u001b[0;36mBaseBlockManager.reindex_indexer\u001b[1;34m(self, new_axis, indexer, axis, fill_value, allow_dups, copy, only_slice, use_na_proxy)\u001b[0m\n\u001b[0;32m    737\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRequested axis not found in manager\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    739\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m axis \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m--> 740\u001b[0m     new_blocks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_slice_take_blocks_ax0\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    741\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    742\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfill_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    743\u001b[0m \u001b[43m        \u001b[49m\u001b[43monly_slice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43monly_slice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    744\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_na_proxy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_na_proxy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    745\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    746\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    747\u001b[0m     new_blocks \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    748\u001b[0m         blk\u001b[38;5;241m.\u001b[39mtake_nd(\n\u001b[0;32m    749\u001b[0m             indexer,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    755\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m blk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblocks\n\u001b[0;32m    756\u001b[0m     ]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\core\\internals\\managers.py:898\u001b[0m, in \u001b[0;36mBaseBlockManager._slice_take_blocks_ax0\u001b[1;34m(self, slice_or_indexer, fill_value, only_slice, use_na_proxy)\u001b[0m\n\u001b[0;32m    896\u001b[0m                     blocks\u001b[38;5;241m.\u001b[39mappend(nb)\n\u001b[0;32m    897\u001b[0m             \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 898\u001b[0m                 nb \u001b[38;5;241m=\u001b[39m \u001b[43mblk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtake_nd\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtaker\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnew_mgr_locs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmgr_locs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    899\u001b[0m                 blocks\u001b[38;5;241m.\u001b[39mappend(nb)\n\u001b[0;32m    901\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m blocks\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\core\\internals\\blocks.py:945\u001b[0m, in \u001b[0;36mBlock.take_nd\u001b[1;34m(self, indexer, axis, new_mgr_locs, fill_value)\u001b[0m\n\u001b[0;32m    942\u001b[0m     allow_fill \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    944\u001b[0m \u001b[38;5;66;03m# Note: algos.take_nd has upcast logic similar to coerce_to_target_dtype\u001b[39;00m\n\u001b[1;32m--> 945\u001b[0m new_values \u001b[38;5;241m=\u001b[39m \u001b[43malgos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtake_nd\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    946\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_fill\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_fill\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfill_value\u001b[49m\n\u001b[0;32m    947\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    949\u001b[0m \u001b[38;5;66;03m# Called from three places in managers, all of which satisfy\u001b[39;00m\n\u001b[0;32m    950\u001b[0m \u001b[38;5;66;03m#  these assertions\u001b[39;00m\n\u001b[0;32m    951\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m, ExtensionBlock):\n\u001b[0;32m    952\u001b[0m     \u001b[38;5;66;03m# NB: in this case, the 'axis' kwarg will be ignored in the\u001b[39;00m\n\u001b[0;32m    953\u001b[0m     \u001b[38;5;66;03m#  algos.take_nd call above.\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\core\\array_algos\\take.py:117\u001b[0m, in \u001b[0;36mtake_nd\u001b[1;34m(arr, indexer, axis, fill_value, allow_fill)\u001b[0m\n\u001b[0;32m    114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mtake(indexer, fill_value\u001b[38;5;241m=\u001b[39mfill_value, allow_fill\u001b[38;5;241m=\u001b[39mallow_fill)\n\u001b[0;32m    116\u001b[0m arr \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(arr)\n\u001b[1;32m--> 117\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_take_nd_ndarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_fill\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\core\\array_algos\\take.py:157\u001b[0m, in \u001b[0;36m_take_nd_ndarray\u001b[1;34m(arr, indexer, axis, fill_value, allow_fill)\u001b[0m\n\u001b[0;32m    155\u001b[0m     out \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mempty(out_shape, dtype\u001b[38;5;241m=\u001b[39mdtype, order\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mF\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    156\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 157\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mempty\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout_shape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    159\u001b[0m func \u001b[38;5;241m=\u001b[39m _get_take_nd_function(\n\u001b[0;32m    160\u001b[0m     arr\u001b[38;5;241m.\u001b[39mndim, arr\u001b[38;5;241m.\u001b[39mdtype, out\u001b[38;5;241m.\u001b[39mdtype, axis\u001b[38;5;241m=\u001b[39maxis, mask_info\u001b[38;5;241m=\u001b[39mmask_info\n\u001b[0;32m    161\u001b[0m )\n\u001b[0;32m    162\u001b[0m func(arr, indexer, out, fill_value)\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 2.44 GiB for an array with shape (26, 100725482) and data type int8"
     ]
    }
   ],
   "source": [
    "model = MultiLabelCatBoostClassifier()\n",
    "\n",
    "#train test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(dataset[[str(x) for x in range(80)]], dataset[[x for x in \"abcdefghijklmnopqrstuvwxyz\"]], test_size=0.01, random_state=42)\n",
    "\n",
    "model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate accuracy between individual columns\n",
    "\n",
    "def accuracy(y_pred, y_test):\n",
    "    cols = y_test.columns\n",
    "    x = []\n",
    "    for i in range(len(cols)):\n",
    "        print(cols[i],\" : \",confusion_matrix(np.round(y_pred[:,i]),y_test[cols[i]]))\n",
    "        print(cols[i],\" : \",balanced_accuracy_score(np.round(y_pred[:,i]),y_test[cols[i]]))\n",
    "        x.append(balanced_accuracy_score(np.round(y_pred[:,i]),y_test[cols[i]]))\n",
    "    return np.mean(x)\n",
    "\n",
    "accuracy(model.predict(X_test),y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('models_trained/multilabel_catboost_model.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "value_rev = {v: k for k, v in value.items()}\n",
    "#array of size 80 with -1s\n",
    "def prediction(tc):\n",
    "    inp = np.array([-1 for x in range(80)])\n",
    "    for i in range(len(tc)):\n",
    "        inp[i] = value[tc[i]]\n",
    "        inp[80-len(tc)+i] = value[tc[i]]\n",
    "\n",
    "    inp = model.predict(np.array([inp]))[0]\n",
    "\n",
    "    perm = \"\"\n",
    "    prob = []\n",
    "    for i in range(26):\n",
    "        perm += alpha[np.argmax(inp)]\n",
    "        prob.append(inp[np.argmax(inp)])\n",
    "        inp[np.argmax(inp)] = -1\n",
    "    return perm, prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a subset of 6 character x which contain only one '_' and the rest are alphabets and replace '_' with '*'\n",
    "def create_substrings(trial,guessed=[],n=6,threshold=0.1,multiple=False):\n",
    "    substring = []\n",
    "    for i in range(len(trial)):\n",
    "        if trial[i] == '_' and i >= 0 and i <= len(trial)-1 :\n",
    "            if multiple:\n",
    "                #replace all '_' with '.'\n",
    "                substring.append((trial[max(i-n+1,0):i] + '.' + trial[i+1:min(i+n,len(trial))]).replace(\"_\",\"*\"))\n",
    "            \n",
    "            if not multiple and (i==0 or trial[i-1] != '_') and (i==len(trial)-1 or trial[i+1] != '_'): \n",
    "                substring.append(trial[max(i-n+1,0):i] + '.' + trial[i+1:min(i+n,len(trial))])\n",
    "    \n",
    "    #if any string in substring has more than two '_' then remove it\n",
    "    substrings = []\n",
    "    for trial in substring:\n",
    "        for i in range(0,len(trial)-n+1):\n",
    "            substrings.append(trial[i:i+n])\n",
    "    \n",
    "    if multiple:\n",
    "        substrings  = [x for x in substrings if x.count('*') < 2]\n",
    "    else:\n",
    "        substrings  = [x for x in substrings if x.count('_') == 0]\n",
    "    \n",
    "    substrings  = [x for x in substrings if len(x) == n]\n",
    "\n",
    "    if(substrings == []):\n",
    "        # print(\"No substring found\")\n",
    "        return None,None\n",
    "    \n",
    "    ans = []\n",
    "    \n",
    "    for x in substrings:\n",
    "        ind = x.index('.')\n",
    "        letters = []\n",
    "\n",
    "        if multiple:\n",
    "            x = x.replace(\"*\",\".\")\n",
    "        \n",
    "        for word in words:\n",
    "            if re.search(x,word):\n",
    "                l = word[re.search(x,word).start()+ind]\n",
    "                if l not in guessed:\n",
    "                    letters.append(l)\n",
    "\n",
    "        if letters == []:\n",
    "            continue\n",
    "        \n",
    "        b = [[a[0],a[1]/len(letters),a[1]] for a in Counter(letters).most_common()]\n",
    "        ans.append(b)\n",
    "    \n",
    "    if ans == []:\n",
    "        # print(\"No substring found\")\n",
    "        return None,None\n",
    "    \n",
    "    #create an array with 26 0s representing all alphabets and then add each letter's probability to it\n",
    "    # print(ans)\n",
    "    bb = np.array([0.0 for aaaaa in range(26)])\n",
    "\n",
    "    for x in ans:\n",
    "        for y in x:\n",
    "            bb[value[y[0]]-1] += y[1]\n",
    "\n",
    "    for i in range(len(bb)):\n",
    "        bb[i] = bb[i]/bb.sum()\n",
    "    # print(bb)\n",
    "    if bb[np.argmax(bb)]<threshold:\n",
    "        return None,None\n",
    "    #return the most probable letter\n",
    "    return value_rev[np.argmax(bb)+1],bb[np.argmax(bb)]\n",
    "\n",
    "trial =\"sur_ers\"\n",
    "guess = ['d','a','r','l','t','m','p','g']\n",
    "\n",
    "print(create_substrings(trial,guess,8,multiple=True))\n",
    "# print(\"not8\")\n",
    "print(create_substrings(trial,guess,7,multiple=True))\n",
    "# print(\"not7\")\n",
    "print(create_substrings(trial,guess,6,multiple=True))\n",
    "# print(\"not6\")\n",
    "print(create_substrings(trial,guess,5,multiple=True))\n",
    "# print(\"not5\")\n",
    "print(create_substrings(trial,guess,4,multiple=True))\n",
    "# print(\"not4\")\n",
    "print(create_substrings(trial,guess,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def guessing(word, guessed_letters,verbose = False):\n",
    "\n",
    "    aa,probs = prediction(word)\n",
    "    # print(aa,probs)\n",
    "\n",
    "    pred_prob = 0\n",
    "\n",
    "    for i in range(len(aa)):\n",
    "        if(aa[i] not in guessed_letters):\n",
    "            pred_letter = aa[i]\n",
    "            pred_prob = probs[i]\n",
    "            break\n",
    "    \n",
    "    a,prob = create_substrings(word,guessed_letters,8,multiple=True)\n",
    "    if a != None and prob > pred_prob:\n",
    "        if verbose:\n",
    "            print(\"used8\",a)\n",
    "        return a\n",
    "    \n",
    "    [a,prob] = create_substrings(word,guessed_letters,7,multiple=True)\n",
    "    if a != None and prob > pred_prob:\n",
    "        if verbose:\n",
    "            print(\"used7\",a)\n",
    "        return a\n",
    "    \n",
    "    [a,prob] = create_substrings(word,guessed_letters,6,multiple=True)\n",
    "    if a != None and prob > pred_prob:\n",
    "        if verbose:\n",
    "            print(\"used6\",a)\n",
    "        return a\n",
    "\n",
    "    [a,prob] = create_substrings(word,guessed_letters,5,multiple=True)\n",
    "    if a != None and prob > pred_prob:\n",
    "        if verbose:\n",
    "            print(\"used5\",a)\n",
    "        return a\n",
    "\n",
    "    [a,prob] = create_substrings(word,guessed_letters,4,multiple=True)\n",
    "    if a != None and prob > pred_prob:\n",
    "        if verbose:\n",
    "            print(\"used4\",a)\n",
    "        return a\n",
    "    \n",
    "    [a,prob] = create_substrings(word,guessed_letters,3)\n",
    "    if a != None and prob > pred_prob:\n",
    "        if verbose:\n",
    "            print(\"used3\",a)\n",
    "        return a\n",
    "    \n",
    "    return pred_letter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a string contianing the permutation of \"abcdefghijklmnopqrstuvwxyz\" in descending order of values in the np array of length 26\n",
    "\n",
    "def tries_taken(word,verbose=False,limit=6):\n",
    "    tc = ['_' for x in word]\n",
    "    tc = \"\".join(tc)\n",
    "    guesslist = []\n",
    "    count=0\n",
    "    # print(tc)\n",
    "    while(1):\n",
    "        if(count>=limit):\n",
    "            return count\n",
    "        i = guessing(tc, guesslist,verbose=verbose)\n",
    "        guesslist.append(i)\n",
    "        if(i in word):\n",
    "            #replace all occurences of i in tc with i at positions in word\n",
    "            if(verbose):\n",
    "                print(\"correct guess : \",i)\n",
    "            for j in range(len(word)):\n",
    "                if(word[j]==i):\n",
    "                    tc = list(tc)\n",
    "                    tc[j]=i\n",
    "                    tc = \"\".join(tc)\n",
    "            if(tc == word):\n",
    "                print(\"word guessed completely : \",tc)\n",
    "                return count\n",
    "        else:\n",
    "            # print(\"wrong guess : \",i)\n",
    "            count+=1\n",
    "\n",
    "        if(verbose):\n",
    "            print(tc , i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_words = random.sample(words,2)\n",
    "aa = []\n",
    "for i in random_words:\n",
    "    # print(i)\n",
    "    aa.append(tries_taken(i,verbose=True,limit=6))\n",
    "#percentage of values less than 6 in aa\n",
    "\n",
    "count = 0\n",
    "for i in aa:\n",
    "    if(i<7):\n",
    "        count+=1\n",
    "print(count/10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
